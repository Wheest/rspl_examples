
include "rsp_queue.inc"
include "rdpq_macros.h"

#define IN_SIZE 136 // 4x(32+2*1) (x8)
#define W_SIZE 9 // 3x3 (x8)
#define OSIZE 64 // 2x32 (x8)

state
{
  vec16 MAT_RES[OSIZE];
  vec16 MAT_IN[IN_SIZE];
  vec16 MAT_W[W_SIZE];
  u32 out_part_h_s;
  u32 out_w_s;
  u32 w_stride_slice_s;
  u32 w_slide_byte_offset_s;
  u32 h_slide_byte_offset_s;
}

command<0> DMAInWeights(u32 addressMatW, u32 size)
{
  addressMatW &= 0xFFFFFF;
  u32<$t0> wsize = size;
  dma_in_async(MAT_W, addressMatW, wsize);
}

command<1> DMAInInputs(u32 addressMatInput, u32 size)
{
  addressMatInput &= 0xFFFFFF;
  u32<$t0> xsize = size;
  dma_in_async(MAT_IN, addressMatInput, xsize);
}

command<3> SetArgs(u32 out_part_h, u32 out_w, u32 w_stride_slice,
                   u32 w_slide_byte_offset, u32<$s0> h_slide_byte_offset)
{
  out_part_h &= 0xFFFFFF;
  store(out_part_h, out_part_h_s);
  store(out_w, out_w_s);
  store(w_stride_slice, w_stride_slice_s);
  store(w_slide_byte_offset, w_slide_byte_offset_s);
  store(h_slide_byte_offset, h_slide_byte_offset_s);
}

/**
 * 3x3 Depthwise Convolution, in channel = 8, out channel = 8
 * For slices of convolution
 * Data layout: channels last
 */
command<2> DepthConv(u32 addressMatOut, u32 out_size)
{
  addressMatOut &= 0xFFFFFF;
  u32<$t0> osize = out_size;

  // Load constants
  u32 out_w = load(out_w_s);
  u32 out_part_h = load(out_part_h_s);
  u32 w_stride_slice = load(w_stride_slice_s);
  u32 w_slide_byte_offset = load(w_slide_byte_offset_s);
  u32 h_slide_byte_offset = load(h_slide_byte_offset_s);

  // VU contains 32 128-bit SIMD registers
  vec16 Wslice00 = load(MAT_W, 0x00);
  vec16 Wslice01 = load(MAT_W, 0x10);
  vec16 Wslice02 = load(MAT_W, 0x20);
  vec16 Wslice10 = load(MAT_W, 0x30);
  vec16 Wslice11 = load(MAT_W, 0x40);
  vec16 Wslice12 = load(MAT_W, 0x50);
  vec16 Wslice20 = load(MAT_W, 0x60);
  vec16 Wslice21 = load(MAT_W, 0x70);
  vec16 Wslice22 = load(MAT_W, 0x80);

  // DMA result out
  u32 xpos_base = MAT_IN;
  u32 out_pos = MAT_RES;

  u32 iters_h = 0;

  // Wait for input slice to be loaded
  dma_await();
  // printf("w_slide_byte_offset: %v\n", w_slide_byte_offset);

  // Iterates over the height of the input matrix
  loop {
    u32 iters_w = 0;
    // Iterates over the width of the input matrix
    loop {
      // Each iteration of this loop calculate a single 3x3
      // sliding window (across all 8 channels)
      u32 xpos = xpos_base;
      vec16 Xslice = load(xpos);
      vec16 yslice = Xslice * Wslice00;

      Xslice = load(xpos, 0x10);
      yslice = Xslice +* Wslice01;

      Xslice = load(xpos, 0x20);
      yslice = Xslice +* Wslice02;

      xpos += w_slide_byte_offset; // ({{in_w}}+2*{{padding}})*8*2
      Xslice = load(xpos);
      yslice = Xslice +* Wslice10;

      Xslice = load(xpos, 0x10);
      yslice = Xslice +* Wslice11;

      Xslice = load(xpos, 0x20);
      yslice = Xslice +* Wslice12;

      xpos += w_slide_byte_offset; // ({{in_w}}+2*{{padding}})*8*2;
      Xslice = load(xpos);
      yslice = Xslice +* Wslice20;

      Xslice = load(xpos, 0x10);
      yslice = Xslice +* Wslice21;

      Xslice = load(xpos, 0x20);
      yslice = Xslice +* Wslice22;

      store(yslice, out_pos); // we could just DMA this back at this point

      // increment
      xpos_base += w_stride_slice; // (8*2*{{stride}} 8 channels * 2 bytes * {{stride}} stride)
      out_pos += 16; // 8*2
      iters_w += 1;
    } while (iters_w < out_w)

      xpos_base += h_slide_byte_offset; // {{kdim_w}}*8*2 (-16)
    iters_h += 1;
  } while (iters_h < out_part_h)


  dma_out(MAT_RES, addressMatOut, osize);
}
